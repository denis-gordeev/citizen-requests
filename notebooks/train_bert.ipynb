{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "2e7a8990-a568-4a68-b35d-bb589285c5fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install torch\n",
    "# !pip install transformers\n",
    "# !pip install datasets\n",
    "# !pip install scikit_learn\n",
    "# !pip install transformers[torch]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d26e750a-74b0-4978-958e-6730100984b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import huggingface_hub\n",
    "# huggingface_hub.login()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "715c2e87-556e-4bc4-9f76-27225e1ac57a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import os\n",
    "import re\n",
    "from glob import glob\n",
    "from pathlib import Path\n",
    "\n",
    "import datasets\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.preprocessing import LabelEncoder, MultiLabelBinarizer\n",
    "import torch\n",
    "import transformers\n",
    "from datasets import load_dataset\n",
    "from sklearn.metrics import f1_score\n",
    "from transformers import (AutoTokenizer, AutoModelForSequenceClassification, \n",
    "                          TrainingArguments, Trainer, EarlyStoppingCallback)\n",
    "from sklearn.model_selection import StratifiedShuffleSplit\n",
    "from datasets import Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "645aad12-acbf-40df-985f-27fdf06eb509",
   "metadata": {},
   "outputs": [],
   "source": [
    "if not os.path.exists(\"train.csv\"):\n",
    "    train = pd.read_csv(\"prime99_train.csv\")\n",
    "    test = pd.read_csv(\"prime99_test.csv\")\n",
    "    k = StratifiedShuffleSplit(test_size=0.1, random_state=42, n_splits=1)\n",
    "    train_index, val_index = list(k.split(train, train[\"Тема\"]))[0]\n",
    "    val = train.loc[val_index]\n",
    "    train = train.loc[train_index]\n",
    "    train.to_csv(\"train.csv\", index=None)\n",
    "    val.to_csv(\"val.csv\", index=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "560781ac-7be4-47af-a91e-f173f93ac6c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def tokenize_function(examples):\n",
    "    return tokenizer(\n",
    "        examples[\"Текст инцидента\"],\n",
    "        max_length=256,\n",
    "        padding='max_length',\n",
    "        truncation=True)\n",
    "\n",
    "def create_dataset(data, split):\n",
    "    data = Dataset.from_pandas(data, split=split).map(tokenize_function, batched=True)\n",
    "    return data\n",
    "\n",
    "model_ckpt = \"xlm-roberta-base\"\n",
    "tokenizer = AutoTokenizer.from_pretrained(\n",
    "    model_ckpt, problem_type=\"single_label_classification\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "27a6e66b-5c4d-4f45-8774-219008eafee5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_metrics(eval_pred):\n",
    "    predictions, labels = eval_pred\n",
    "    output = dict()\n",
    "    for average in (\"macro\", \"micro\", \"weighted\"):\n",
    "        score = f1_score(labels,\n",
    "                         np.argmax(predictions, axis=1),\n",
    "                         average=average)\n",
    "        output[f\"f1_{average}\"] = score\n",
    "    return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "c5f92548-0930-4bf5-bb59-f900419600fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# def train_model(train, val, test, column=\"Исполнитель\"):\n",
    "column = \"Группа тем\"\n",
    "start_df = pd.read_csv(\"prime99_train.csv\")\n",
    "label_encoder = LabelEncoder()\n",
    "label_encoder.fit(start_df[column])\n",
    "\n",
    "datasets = [\"train\", \"val\", \"prime99_test\"]\n",
    "dataset_dict = dict()\n",
    "for dataset in datasets:\n",
    "    df = pd.read_csv(f\"{dataset}.csv\")\n",
    "    df[\"label\"] = label_encoder.transform(df[column])\n",
    "    hf_dataset = create_dataset(df, dataset)\n",
    "    dataset_dict[dataset] = hf_dataset\n",
    "    \n",
    "model = AutoModelForSequenceClassification.from_pretrained(\n",
    "    model_ckpt,\n",
    "    num_labels=len(label_encoder.classes_),\n",
    "    problem_type=\"single_label_classification\").to('cuda')\n",
    "\n",
    "\n",
    "batch_size = 32\n",
    "\n",
    "args = TrainingArguments(\n",
    "    output_dir=\"multiclass_model\",\n",
    "    evaluation_strategy=\"epoch\",\n",
    "    save_strategy=\"epoch\",\n",
    "    learning_rate=2e-5,\n",
    "    per_device_train_batch_size=batch_size,\n",
    "    per_device_eval_batch_size=batch_size,\n",
    "    num_train_epochs=10,\n",
    "    weight_decay=0.01,\n",
    "    save_total_limit=5,\n",
    "    metric_for_best_model=\"f1_macro\",\n",
    "    load_best_model_at_end=True,\n",
    "    \n",
    ")\n",
    "\n",
    "trainer = Trainer(\n",
    "    model,\n",
    "    args,\n",
    "    train_dataset=dataset_dict[\"train\"],\n",
    "    eval_dataset=dataset_dict[\"val\"],\n",
    "    compute_metrics=compute_metrics,\n",
    "    tokenizer=tokenizer,\n",
    "    callbacks = [EarlyStoppingCallback(early_stopping_patience=3)]\n",
    ")\n",
    "trainer.evaluate()\n",
    "trainer.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "7860f28d-85d1-414d-9809-93d44e64ebc3",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch import nn\n",
    "sigmoid = nn.Sigmoid()\n",
    "\n",
    "def inference(model, message, **kwargs):\n",
    "    input_ids, attention_mask = tokenize(message, **kwargs)\n",
    "    preds = model(input_ids, attention_mask)\n",
    "    logits = sigmoid(preds[\"logits\"])[0].cpu().detach().numpy()\n",
    "    return logits\n",
    "\n",
    "def tokenize(message, device=\"cuda\", **kwargs):\n",
    "    text_enc = tokenizer.encode_plus(\n",
    "        message,\n",
    "        None,\n",
    "        add_special_tokens=True,\n",
    "        max_length=256,\n",
    "        padding=\"max_length\",\n",
    "        return_token_type_ids=False,\n",
    "        return_attention_mask=True,\n",
    "        truncation=True,\n",
    "        return_tensors=\"np\",\n",
    "    )\n",
    "    input_ids = torch.tensor(text_enc[\"input_ids\"], dtype=torch.long).to(device)\n",
    "    attention_mask = torch.tensor(text_enc[\"attention_mask\"], dtype=torch.long).to(\n",
    "        device\n",
    "    )\n",
    "    return input_ids, attention_mask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "d9f3c041-f3ac-46a2-94b9-2c6a52d88a82",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "26"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(label_encoder.classes_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "d49b6bcf-ae67-40e9-bb3d-bf39460a2935",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7504600839262756"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test = pd.read_csv(\"prime99_test.csv\")\n",
    "preds = [label_encoder.inverse_transform([np.argmax(inference(model2, text))])[0]\n",
    "         for text in test[\"Текст инцидента\"].values]\n",
    "f1_score(test[column], preds, average=\"weighted\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "d8bf478c-090a-474a-b5f9-20d1f68a9e3b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['Безопасность', 'Благоустройство', 'Газ и топливо',\n",
       "       'Государственная собственность', 'Дороги', 'ЖКХ',\n",
       "       'Здравоохранение/Медицина', 'Коронавирус', 'Культура',\n",
       "       'МФЦ \"Мои документы\"', 'Мобилизация', 'Мусор/Свалки/ТКО',\n",
       "       'Образование', 'Общественный транспорт',\n",
       "       'Памятники и объекты культурного наследия',\n",
       "       'Погребение и похоронное дело', 'Роспотребнадзор',\n",
       "       'Связь и телевидение', 'Социальное обслуживание и защита',\n",
       "       'Спецпроекты', 'Строительство и архитектура', 'Торговля',\n",
       "       'Физическая культура и спорт', 'Экология', 'Экономика и бизнес',\n",
       "       'Электроснабжение'], dtype=object)"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "label_encoder.classes_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "dc4afbb7-d4ad-4511-bab5-bc62e9efe977",
   "metadata": {},
   "outputs": [],
   "source": [
    "bert_classes = {c: ci for ci, c in enumerate(bert_label_encoder.classes_)}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "0120bb32-11cf-4678-b0e4-618068239d02",
   "metadata": {},
   "outputs": [],
   "source": [
    "bert_probas = inference(group_roberta_model, input_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "7c859fe3-9d7c-4a1e-9885-c412a084365e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.5637781 , 0.726879  , 0.23757683, 0.16903396, 0.6920174 ,\n",
       "       0.8380316 , 0.99354136, 0.8742636 , 0.23495382, 0.13958792,\n",
       "       0.2907984 , 0.8348023 , 0.48864707, 0.44516757, 0.12066784,\n",
       "       0.1485628 , 0.1616542 , 0.784488  , 0.8539515 , 0.37535444,\n",
       "       0.3281864 , 0.08632873, 0.16671015, 0.10712508, 0.1850831 ,\n",
       "       0.22988942], dtype=float32)"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bert_probas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "d8a5f65a-2657-46dc-8c97-bf51f34d2f32",
   "metadata": {},
   "outputs": [],
   "source": [
    "input_text = \"медицина\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "7c9644b5-c859-4475-a37e-bbb64183f8d1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.5637781 , 0.726879  , 0.23757683, 0.16903396, 0.6920174 ,\n",
       "       0.8380316 , 0.99354136, 0.8742636 , 0.23495382, 0.13958792,\n",
       "       0.2907984 , 0.8348023 , 0.48864707, 0.44516757, 0.12066784,\n",
       "       0.1485628 , 0.1616542 , 0.784488  , 0.8539515 , 0.37535444,\n",
       "       0.3281864 , 0.08632873, 0.16671015, 0.10712508, 0.1850831 ,\n",
       "       0.22988942], dtype=float32)"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "inference(model2, \"медицина\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "19113f67-dc31-49a2-b5e8-332eef1b6aef",
   "metadata": {},
   "outputs": [],
   "source": [
    "group_roberta_model = model2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "806a1774-2b5c-4aa7-ba34-5f98e4628266",
   "metadata": {},
   "outputs": [],
   "source": [
    "bert_probas = inference(group_roberta_model, \"медицина\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "256948a3-ec3a-41d2-bf0c-e81f9c4f393f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "with open(\"theme_group_label_encoder.pcl\", \"wb\") as f:\n",
    "    pickle.dump(label_encoder, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "e746f480-bc27-4080-b1e4-892c80db3ae0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# datasets = [\"train\", \"val\", \"prime99_test\"]\n",
    "# dataset_dict = dict()\n",
    "# for dataset in datasets:\n",
    "#     df = pd.read_csv(f\"{dataset}.csv\")\n",
    "#     preds = [label_encoder.inverse_transform([np.argmax(inference(model, text))])[0] for text in df[\"Текст инцидента\"].values]\n",
    "#     preds = [p + \";\" for p in preds]\n",
    "#     df[\"Текст инцидента\"] = preds + df[\"Текст инцидента\"]\n",
    "#     df.to_csv(f\"{dataset}.csv\", index=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "b0003142-e89b-40b2-b41c-8ce3eff893c3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "51e643699ea94ea8a4575127bd3ea9b0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model.safetensors:   0%|          | 0.00/1.11G [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "CommitInfo(commit_url='https://huggingface.co/denis-gordeev/xlm-roberta-base-theme/commit/e7626226016e18df6d6c1227994adfc20bed1873', commit_message='Upload XLMRobertaForSequenceClassification', commit_description='', oid='e7626226016e18df6d6c1227994adfc20bed1873', pr_url=None, pr_revision=None, pr_num=None)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.push_to_hub(\"denis-gordeev/xlm-roberta-base-theme\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "c5992c41-70c4-4d85-94d3-e5b141d5a304",
   "metadata": {},
   "outputs": [],
   "source": [
    "model2 = AutoModelForSequenceClassification.from_pretrained(\n",
    "    \"denis-gordeev/xlm-roberta-base-theme-group\",\n",
    "    problem_type=\"single_label_classification\").to('cuda')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
